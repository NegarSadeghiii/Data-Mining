# Board Game Recommender Systems

## Overview

This project builds several board-game recommender systems using the **All Files** dataset scraped from BoardGameGeek.

It includes:
- Collaborative filtering models  
- A hybrid deep learning model  
- A neural matrix factorization (NMF) model  
- An advanced NLP content-based recommender  
- An optional ensemble of the trained models  

All experiments are implemented in `advanced_bgg_recommender_system.ipynb`.

---

## Data

The project assumes the following folder structure inside `All Files`:

- `All Files/cleaned_statistics`  
  - 119,978 games with metadata (players, play time, ratings, categories, mechanics, etc.)

- `All Files/ratings1.csv` … `ratings38.csv`  
  - ~3.7M user ratings for the 2,000 most reviewed games  
  - Columns include: game ID, user, rating, and (optionally) comment

- Additional artifacts (e.g., `games_to_*`, `games_with_descriptions`)  
  - These can be regenerated by re-running the scrapers, but the main notebook **only relies on the provided files**.

---

## Workflow

### 1. Setup

1. Upload the **All Files** folder to your Google Colab workspace.  
2. Open `advanced_bgg_recommender_system.ipynb`.  
   - The notebook auto-detects the location of `cleaned_statistics` and the ratings CSVs.
3. For reasonable training time, enable a GPU (T4 recommended):  
   - **Runtime → Change runtime type → Hardware accelerator → GPU**  
4. GPU detection is automatic; the notebook adjusts batch sizes and memory growth accordingly.

---

### 2. Preprocessing

The notebook performs the following steps:

- Loads data into Pandas, converts ratings to numeric, and filters out invalid rows.  
- Restricts the dataset to the most-reviewed games (2,000 by default) and label-encodes game and user IDs.  
- Standardizes numeric features and builds combined text fields for content-based models.  
- Provides a configuration block to **sample down the dataset** via `USE_SAMPLE=True` for faster experimentation (e.g., cap at 500 games and 100k ratings) while preserving structure.

---

### 3. Models

The notebook supports the following models:

- **Neural Collaborative Filtering (NCF)**  
- **Hybrid Model**  
  - Combines user/item embeddings with game feature vectors  
- **Neural Matrix Factorization (Neural MF)**  
- **Advanced NLP Content-Based Recommender**  
  - Based on Sentence Transformers or TF-IDF representations of game text  
- **Ensemble (Optional)**  
  - Combines predictions from the neural models

---

### 4. Ensemble Evaluation

Ensemble evaluation is more time-consuming because it:

- Builds a game-feature lookup table  
- Scores each test interaction using multiple underlying models  

To keep regular experiments fast:

- Ensemble evaluation is controlled by a toggle: `RUN_ENSEMBLE_EVAL`.  
- Leave it **off** for quick runs.  
- Turn it **on** when you want to compute full ensemble metrics.

---

### 5. Evaluation Metrics

**Collaborative models** (NCF, Hybrid, Neural MF) predict **numeric ratings** and are evaluated using:

- MSE  
- RMSE  
- MAE  

**Content-based model** (NLP recommender) produces **ranked lists**, not raw ratings, so it is evaluated with:

- Hit@K  
- Precision@K  
- MRR@K  
- Coverage statistics  

These ranking metrics better capture how well the model surfaces relevant games in a top-N recommendation list.

The notebook includes visualization cells that:

- Plot collaborative errors (MSE/RMSE/MAE)  
- Plot ranking metrics for the content-based model separately

---

### 6. Visualization & Recommendation Examples

The notebook provides:

- Comparative bar charts for collaborative model errors (MSE, RMSE, MAE)  
- Separate bar charts for content-based ranking metrics  
- Utility cells that:
  - Show top-N recommendations for specific users  
  - Find the most similar games given a title  

---

## Recommended Usage

1. **Upload data** and run the notebook from top to bottom.  
2. Start with `USE_SAMPLE=True` for rapid iteration and debugging.  
3. Once the pipeline works, switch to the full dataset (GPU strongly recommended).  
4. Train the NCF, Hybrid, and Neural MF models and review their collaborative metrics.  
5. Run the content-based evaluation cell to obtain ranking metrics.  
6. Optionally enable `RUN_ENSEMBLE_EVAL` to compute ensemble performance.  
7. Review comparison plots and recommendation examples, then adjust configuration or model settings as needed.


================================================================================================================================================
Operational Forecasting for HHS Hospital Capacity

Overview
This project focuses on operational forecasting of hospital capacity using publicly available data from the U.S. Department of Health and Human Services (HHS). The objective is to analyze historical trends and build predictive insights related to hospital utilization, such as inpatient beds, ICU capacity, and overall system stress.

The work is implemented as a Jupyter Notebook and is intended for exploratory analysis, forecasting practice, and operational decision support in healthcare systems.

File Description
Operational Forecasting (HHS Hospital Capacity).ipynb
This notebook contains data loading, preprocessing, exploratory data analysis, and forecasting components applied to hospital capacity metrics reported by HHS. All analysis steps are documented and executed sequentially within the notebook.

Data Source
The analysis uses HHS hospital capacity data, which includes regularly reported operational metrics from hospitals across the United States. These data capture system-level capacity signals commonly used for public health monitoring and planning.

Methodology
The notebook begins with data cleaning and transformation to ensure consistency across time and reporting entities. Exploratory analysis is performed to identify trends, seasonality, and anomalies in hospital capacity indicators.

Forecasting techniques are then applied to model future capacity behavior based on historical patterns. The emphasis is on operational interpretability rather than purely predictive accuracy, aligning the analysis with real-world healthcare planning needs.

Requirements
The notebook is written in Python and relies on standard data science libraries such as pandas, NumPy, Matplotlib, and forecasting or statistical modeling packages depending on the methods used. The analysis runs in a standard Jupyter Notebook environment.

How to Run
Open the notebook using Jupyter Notebook or Jupyter Lab and execute the cells in order. All parameters and assumptions are defined within the notebook and can be adjusted to explore different forecasting horizons or capacity measures.

Outputs and Interpretation
The notebook produces time-series visualizations, summary statistics, and forecast plots that illustrate hospital capacity trends and projected future behavior. These outputs are intended to support high-level operational insights.

Use Case and Scope
This project is suitable for coursework, applied analytics projects, or portfolio demonstrations focused on healthcare operations forecasting. It is not intended for real-time clinical decision making or policy enforcement.

Notes
The analysis emphasizes clarity and reproducibility. All steps are contained within a single notebook to make the workflow easy to follow and adapt for related healthcare forecasting problems.

